[{"path":"https://rkrug.github.io/openalexPro/articles/Workflow.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Workflow using openalexPro2","text":"package openalexPro2 extension package openalexR. main difference openalexR processing memory returns result R object, openalexPro2 write results disk. allows processing large corpora. processing done using duckdb package makes possible tro complex queries corpora without need load whole corpus memory.","code":""},{"path":"https://rkrug.github.io/openalexPro/articles/Workflow.html","id":"workflow","dir":"Articles","previous_headings":"","what":"Workflow","title":"Workflow using openalexPro2","text":"workflow using openalexPro2 essentially follows: function openalexPro2::pro_query() used build API query OpenAlex API function openalexPro2::pro_request() used retrieve results OpenAlex API store folder format oif json files returned OpenAlex. function openalexPro2::pro_request_jsonl() cleaning editing json files Json Lines, aka NDJSON, atext file line separate JSON object. details see function openalexPro2::pro_request_jsonl_parquet() used convert json files parquet database TODO: Add plantuml graph TODO add info examles","code":""},{"path":"https://rkrug.github.io/openalexPro/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Rainer M Krug. Maintainer.","code":""},{"path":"https://rkrug.github.io/openalexPro/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Krug RM (2025). openalexPro: Providing advanced access OpenAlex power user. R package version 0.3.0, https://github.com/rkrug/openalexPro.","code":"@Manual{,   title = {openalexPro: Providing a more advanced access to OpenAlex for the power user},   author = {Rainer M Krug},   year = {2025},   note = {R package version 0.3.0},   url = {https://github.com/rkrug/openalexPro}, }"},{"path":[]},{"path":"https://rkrug.github.io/openalexPro/index.html","id":"llm-usage-disclosure","dir":"","previous_headings":"","what":"LLM Usage Disclosure","title":"Providing a more advanced access to OpenAlex for the power user","text":"Code documentation project generated assistance codex LLM tools Positron. content code based conceptuaisayion authors thoroughly reviewed edited humans afterwards.","code":""},{"path":"https://rkrug.github.io/openalexPro/index.html","id":"introduction","dir":"","previous_headings":"","what":"Introduction","title":"Providing a more advanced access to OpenAlex for the power user","text":"package builds package openalexR provides advanced approach retrieve works OpenAlex. contrast openalexR, processing conversions memory. processing memory advantages smaller smaller number records retrieved OpenAlex, limits te number works can retrieved due memory limitations. Even limit reached, often occurring new allocation memory slows processing. first step, contrast, openalexPro uses disc processing approach data processed number records returned per call, .e. per page processing approach.","code":""},{"path":"https://rkrug.github.io/openalexPro/index.html","id":"design-principles","dir":"","previous_headings":"","what":"Design Principles","title":"Providing a more advanced access to OpenAlex for the power user","text":"retrieval works initial processing / preparation can split three steps: first step (openalexPro::pro_request()), page API call saved individual json file returned API. number retrieved records effectively limited space drive json files saved. complete responses including metadata saved, one end use custom made code process responses, .e. ingest database. second step (openalexPro::pro_request_jsonl()), json files processed per file basis using jq command-line json processor. step abstract text re-constructed, citation string work generated, optionally add page field added. writes resulting json file newline-delimited JSON (.jsonl), suitable processing using arrow DuckDB. Int third (final) step (openalexPro::pro_request_jsonl_parquet()) converts jsonl files parquet database partitioned page using duckdb package. , processing done per page well, conversion limited memory. approach results stable pipeline works retrieval small well large huge corpora. processing done per page (maximum 200 works), scaling less linear (one application, 4 million works retrieved without problems). One point needs taken consideration retrieving huge corpora, rate limits OpenAlex (see details). final format used package save retrieved data parquet format space efficient allows disc processing, therefor need load complete data memory (see detailed description format well r-package arrow). use disc processing R, arrow packages interfaces directly dplyr, one can lot processing retrieving actual data memory (see section dplyr arrow well general arrow chapter Hadleys Wickhams R Data Science (2e) bookhttps://r4ds.hadley.nz).","code":""},{"path":[]},{"path":"https://rkrug.github.io/openalexPro/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Providing a more advanced access to OpenAlex for the power user","text":"latest “stable” version available via r-universe “development” version can installed github. generally recommended! Unless need bleeding edge functionality can deal changing function definitions, whant test new functionality, recommended.","code":"install.packages('openalexPro', repos = c('https://rkrug.r-universe.dev', 'https://cloud.r-project.org')) remotes::install_github(\"rkrug/openalexPro\", ref = \"dev\")"},{"path":"https://rkrug.github.io/openalexPro/index.html","id":"basic-workflow-for-searches","dir":"","previous_headings":"","what":"Basic Workflow for Searches","title":"Providing a more advanced access to OpenAlex for the power user","text":"First, package needs loaded","code":"library(openalexPro)"},{"path":"https://rkrug.github.io/openalexPro/index.html","id":"id_1-define-query-openalexpropro_query","dir":"","previous_headings":"Basic Workflow for Searches","what":"1. Define query (openalexPro:pro_query())","title":"Providing a more advanced access to OpenAlex for the power user","text":"query defined using function openalexPro:pro_query(). follows logic arguments openalexR::oa_query(). addition openalexR::oa_query(), names filters well fields selected retrieval verified sending OpenAlex. supported filter names can retrieved running supported select fields running defines basic query. returns URL, one can open browser. , however, example 100 DOIs given retrieved, query chunked chunks maximum value argument chunk_limit, default 50. case, functions returns list() element named Chunk_x containing URL character vector.","code":"opt_filter_names() opt_select_fields() query <- pro_query(   title_and_abstract.search = \"biodiversity AND conservation AND IPBES\",   entity = \"works\" )"},{"path":"https://rkrug.github.io/openalexPro/index.html","id":"id_2-retrieving-records-openalexpropro_request","dir":"","previous_headings":"Basic Workflow for Searches","what":"2. Retrieving records (openalexPro::pro_request())","title":"Providing a more advanced access to OpenAlex for the power user","text":"retrieve records save folder specified output. One important difference now query single URL list: list, future future.apply packages used process URLs list parallel.","code":"openalexPro::pro_request(   query_url = query,   output = \"json\",   verbose = TRUE )"},{"path":"https://rkrug.github.io/openalexPro/index.html","id":"id_3-processing-json-files-openalexpropro_request_jsonl","dir":"","previous_headings":"Basic Workflow for Searches","what":"3. Processing json files (openalexPro::pro_request_jsonl())","title":"Providing a more advanced access to OpenAlex for the power user","text":"step prepares json files final ingestion parquet database: resulting json files can found folder specified output.","code":"openalex_jsonl_folder <- openalexPoro2::pro_request_jsonl(   input_json = \"json_files\",   output = json_extracted,   verbose = TRUE )"},{"path":"https://rkrug.github.io/openalexPro/index.html","id":"id_4-convert-to-parquet-database-openalexpropro_request_jsonl_parquet","dir":"","previous_headings":"Basic Workflow for Searches","what":"4. Convert to parquet database (openalexPro::pro_request_jsonl_parquet())","title":"Providing a more advanced access to OpenAlex for the power user","text":"files converted parquet page partitioned dataset saved individual parquet files folder provided output argument.","code":"parquet <- \"./parquet\" openalexPro::pro_request_jsonl_parquet(   json_dir = json_extracted,   output = parquet,   verbose = TRUE )"},{"path":"https://rkrug.github.io/openalexPro/index.html","id":"convenience-function-to-read-the-retrieved-data-openalexproread_corpus","dir":"","previous_headings":"Basic Workflow for Searches","what":"Convenience Function to Read the Retrieved Data (openalexPro::read_corpus())","title":"Providing a more advanced access to OpenAlex for the power user","text":"read_corpus() function reads corpus either arrow Dataset object return_data = FALSE, essentially metadata dataset, data.frame, .e. data table, return_data = TRUE, case whole dataset loaded memory.","code":""},{"path":"https://rkrug.github.io/openalexPro/index.html","id":"basic-workflow-for-snowball-searches","dir":"","previous_headings":"","what":"Basic Workflow for Snowball Searches","title":"Providing a more advanced access to OpenAlex for the power user","text":"function openalexR::oa_snowball(), openalexPro provides snowball function stores results parquet database, can red compatible firmat openalexR::oa_snowball(). Snowball searches based following citation graph identify cited citing works, starting set key-works.","code":""},{"path":"https://rkrug.github.io/openalexPro/index.html","id":"id_1-define-keypapers","dir":"","previous_headings":"Basic Workflow for Snowball Searches","what":"1. Define Keypapers","title":"Providing a more advanced access to OpenAlex for the power user","text":"keypapers can identified either DOIs OpenAlex ids.","code":""},{"path":"https://rkrug.github.io/openalexPro/index.html","id":"id_2-do-the-snowball-search","dir":"","previous_headings":"Basic Workflow for Snowball Searches","what":"2. Do the snowball search","title":"Providing a more advanced access to OpenAlex for the power user","text":"snowball search creates several sub-folders output folder (assumed called snowball): contain following files: raw json files returned (cited_json, citing_json, keypaper_json), processsed json files (cited_jsonl, citing_jsonl, keypaper_jsonl), parquet database keypaper (keypaper_parquet) nodes edges snowball search parquet databases.","code":"snowball/ ├── cited_json/ ├── cited_jsonl/ ├── citing_json/ ├── citing_jsonl/ ├── edges/ ├── keypaper_json/ ├── keypaper_jsonl/ ├── keypaper_parquet/ └── nodes/"},{"path":"https://rkrug.github.io/openalexPro/index.html","id":"use-openalex-ids","dir":"","previous_headings":"Basic Workflow for Snowball Searches > 2. Do the snowball search","what":"Use OpenAlex ids","title":"Providing a more advanced access to OpenAlex for the power user","text":"","code":"snowball_dir <- \"./snowball_ids\" snowball_docs <- pro_snowball(   identifier = c(\"W2741809807\", \"W2755950973\"),   output = snowball_dir,   verbose = TRUE )"},{"path":"https://rkrug.github.io/openalexPro/index.html","id":"use-dois","dir":"","previous_headings":"Basic Workflow for Snowball Searches > 2. Do the snowball search","what":"Use DOIs","title":"Providing a more advanced access to OpenAlex for the power user","text":"","code":"snowball_dir_dois <- \"./snowball_dois\" oa_snowball(   doi = c(\"10.1016/j.joi.2017.08.007\", \"10.7717/peerj.4375\"),   output = snowball_dir_dois,   verbose = TRUE )"},{"path":"https://rkrug.github.io/openalexPro/index.html","id":"convenience-function-to-read-the-retrieved-data-openalexproread_snowball","dir":"","previous_headings":"Basic Workflow for Snowball Searches","what":"Convenience Function to Read the Retrieved Data (openalexPro::read_snowball())","title":"Providing a more advanced access to OpenAlex for the power user","text":"function read_snowball() reads snowball search. function returns, return_data = TRUE either list contains list two elements, nodes edges. structure list functional identical one returned openalexR::oa_snowball() regards network structure. return_data = FALSE returns dataset object","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/compatibility_report.html","id":null,"dir":"Reference","previous_headings":"","what":"Render and open the compatibility report — compatibility_report","title":"Render and open the compatibility report — compatibility_report","text":"Renders Quarto report `system.file(\"compatibility.qmd\", package = \"openalexPro\") opens resulting HTML default browser.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/compatibility_report.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Render and open the compatibility report — compatibility_report","text":"","code":"compatibility_report(   output_dir = \"Compatibility Report\",   open = TRUE,   quiet = FALSE )"},{"path":"https://rkrug.github.io/openalexPro/reference/compatibility_report.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Render and open the compatibility report — compatibility_report","text":"output_dir Directory write rendered HTML data . Defaults flder `./Compatibility Report`. open Logical; `TRUE` (default) opens rendered HTML system browser. quiet Logical; suppress rendering output `TRUE`. Default: `FALSE`.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/compatibility_report.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Render and open the compatibility report — compatibility_report","text":"Invisibly returns path rendered HTML file.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/compatibility_report.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Render and open the compatibility report — compatibility_report","text":"report designed help validate client–API compatibility real time. rendering, report performs live requests OpenAlex API compares responses package's expected behavior. cached data used: every section issues fresh API calls output reflects current state upstream service. report summarizes differences fields, types, pagination response shapes surface potential regressions upstream changes local client updates. Note: depends live API calls, rendering may take longer requires network access. mindful API rate limits running report repeatedly.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/extract_doi.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract DOIs or Components from Character Vectors — extract_doi","title":"Extract DOIs or Components from Character Vectors — extract_doi","text":"Extracts DOIs specific DOI components (resolver, prefix, suffix) character vector. Assumes element `x` contains one DOI (without resolver).","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/extract_doi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract DOIs or Components from Character Vectors — extract_doi","text":"","code":"extract_doi(   x,   non_doi_value = \"\",   normalize = TRUE,   what = c(\"doi\", \"resolver\", \"prefix\", \"suffix\") )"},{"path":"https://rkrug.github.io/openalexPro/reference/extract_doi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract DOIs or Components from Character Vectors — extract_doi","text":"x character vector potentially containing DOIs (e.g., raw DOIs, DOI URLs, strings embedded DOIs). non_doi_value Value use elements DOI component found. `NULL`, matched elements returned. normalize Logical. `TRUE` (default), convert extracted DOIs suffixes lowercase trim surrounding whitespace. effect `= \"prefix\"` `= \"resolver\"`. extract element. One : \"doi\" full DOI name (prefix + \"/\" + suffix). Example: `\"10.5281/zenodo.1234567\"` (default) \"resolver\" resolver URL (e.g., `\"https://doi.org/\"`, `\"http://dx.doi.org/\"`) present \"prefix\" DOI prefix (e.g., `\"10.5281\"`) \"suffix\" DOI suffix (e.g., `\"zenodo.1234567\"`)","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/extract_doi.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract DOIs or Components from Character Vectors — extract_doi","text":"character vector:   - `non_doi_value` `NULL`, vector length `x`, unmatched entries replaced.   - `non_doi_value` `NULL`, vector matched entries.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/extract_doi.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract DOIs or Components from Character Vectors — extract_doi","text":"","code":"x <- c(   \"https://doi.org/10.5281/zenodo.1234567\",   \" 10.1000/XYZ456  \",   \"no doi here\",   NA )  extract_doi(x)  # Full DOIs (default) #> [1] \"10.5281/zenodo.1234567\" \"10.1000/xyz456\"         \"\"                       #> [4] \"\"                       extract_doi(x, what = \"resolver\") #> [1] \"https://doi.org/\" \"\"                 \"\"                 \"\"                 extract_doi(x, what = \"prefix\") #> [1] \"10.5281\" \"10.1000\" \"\"        \"\"        extract_doi(x, what = \"suffix\") #> [1] \"zenodo.1234567\" \"xyz456\"         \"\"               \"\"               extract_doi(x, non_doi_value = NA_character_) #> [1] \"10.5281/zenodo.1234567\" \"10.1000/xyz456\"         NA                       #> [4] NA                       extract_doi(x, non_doi_value = NULL) #> [1] \"10.5281/zenodo.1234567\" \"10.1000/xyz456\""},{"path":"https://rkrug.github.io/openalexPro/reference/jq_execute.html","id":null,"dir":"Reference","previous_headings":"","what":"Execute a jq transformation from an OpenAlex-style JSON to JSONL — jq_execute","title":"Execute a jq transformation from an OpenAlex-style JSON to JSONL — jq_execute","text":"function runs jq filter extract records \"results\" array (root type = \"single\"), reconstruct abstract text, generate citation string, optionally add page field. writes result newline-delimited JSON (.jsonl), suitable Arrow DuckDB. details jq filter logic, see vignette(\"jq\", package = \"openalexPro\").","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/jq_execute.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Execute a jq transformation from an OpenAlex-style JSON to JSONL — jq_execute","text":"","code":"jq_execute(   input_json,   output_jsonl,   add_columns = list(),   jq_filter = NULL,   page = NULL,   type = c(\"results\", \"single\", \"group_by\") )"},{"path":"https://rkrug.github.io/openalexPro/reference/jq_execute.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Execute a jq transformation from an OpenAlex-style JSON to JSONL — jq_execute","text":"input_json Path input JSON file output_jsonl Path output .jsonl file add_columns List additional fields added output. nave provided named list, e./g. `list(column_1 = \"value_1\", column_2 = 2)`. Scalar values supported. jq_filter Optional custom jq filter string. NULL, default filter used. page Optional integer added \"page\" field output record type Either \"results\" (default, expects .results[] array) \"single\" (treat input array records directly)","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/jq_execute.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Execute a jq transformation from an OpenAlex-style JSON to JSONL — jq_execute","text":"Invisibly returns output path","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/load_sql_file.html","id":null,"dir":"Reference","previous_headings":"","what":"Load a SQL file — load_sql_file","title":"Load a SQL file — load_sql_file","text":"Load SQL file, remove comments starting \"–\" return SQL single string.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/load_sql_file.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load a SQL file — load_sql_file","text":"","code":"load_sql_file(sql_file = NULL)"},{"path":"https://rkrug.github.io/openalexPro/reference/load_sql_file.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load a SQL file — load_sql_file","text":"sql_file path SQL file.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/load_sql_file.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load a SQL file — load_sql_file","text":"string containing SQL code c executed e.g.   `DBI::dbExecute(conn, sql)`","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/normalize_parquet.html","id":null,"dir":"Reference","previous_headings":"","what":"Normalize parquet files — normalize_parquet","title":"Normalize parquet files — normalize_parquet","text":"function takes directory parquet files normalizes schemata. NB: partitioning input parquet dataset lost!","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/normalize_parquet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Normalize parquet files — normalize_parquet","text":"","code":"normalize_parquet(   input_dir = NULL,   output_dir = NULL,   overwrite = FALSE,   ROW_GROUP_SIZE = 10000,   ROW_GROUPS_PER_FILE = 1,   delete_input = FALSE )"},{"path":"https://rkrug.github.io/openalexPro/reference/normalize_parquet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Normalize parquet files — normalize_parquet","text":"input_dir directory parquet files parquet dataset. output_dir parquet dataset normalized schemata. Non partitioned, split several files. overwrite Determines uputput parquet database shlud overwritten exists. Defauls FALSE. ROW_GROUP_SIZE Maximum number rows per row group. Smaller sizes reduce memory usage, larger sizes improve compression. Defaults 10000. See: https://duckdb.org/docs/sql/statements/copy#row_group_size details. ROW_GROUPS_PER_FILE Number row groups include output Parquet file. Controls file size write frequency. Defaults 1 See: https://duckdb.org/docs/sql/statements/copy#row_groups_per_file details. delete_input Determines inputdir deleted afterwards. Defaults FALSE.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/normalize_parquet.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Normalize parquet files — normalize_parquet","text":"function return output_dir.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/normalize_parquet.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Normalize parquet files — normalize_parquet","text":"function uses DuckDB normalize schemata. function creates DuckDB connection memory reads parquet files DuckDB needed re-writes non-partitioned parquet database normalized schemata.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/oap_apikey.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the OpenAlex API key for requests — oap_apikey","title":"Get the OpenAlex API key for requests — oap_apikey","text":"Retrieves API key used OpenAlex requests. value taken environment variable openalexR.apikey set; otherwise falls back R option openalexR.apikey. neither defined, NULL returned.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/oap_apikey.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the OpenAlex API key for requests — oap_apikey","text":"","code":"oap_apikey()"},{"path":"https://rkrug.github.io/openalexPro/reference/oap_apikey.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the OpenAlex API key for requests — oap_apikey","text":"character scalar API key, NULL configured.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/oap_apikey.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get the OpenAlex API key for requests — oap_apikey","text":"helper mirrors behavior openalexR::oa_apikey() make easy configure credentials without hard dependency. Prefer setting environment variable non-interactive usage.","code":""},{"path":[]},{"path":"https://rkrug.github.io/openalexPro/reference/oap_apikey.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get the OpenAlex API key for requests — oap_apikey","text":"","code":"# Set via environment (preferred in non-interactive contexts) Sys.setenv(openalexR.apikey = \"<api-key>\") oap_apikey() #> [1] \"<api-key>\"  # Or via options options(openalexR.apikey = \"<api-key>\") oap_apikey() #> [1] \"<api-key>\""},{"path":"https://rkrug.github.io/openalexPro/reference/oap_mail.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the contact email for OpenAlex requests — oap_mail","title":"Get the contact email for OpenAlex requests — oap_mail","text":"Retrieves contact email address used User-Agent header OpenAlex requests. value taken environment variable openalexR.mailto set; otherwise falls back R option openalexR.mailto. neither defined, NULL returned.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/oap_mail.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the contact email for OpenAlex requests — oap_mail","text":"","code":"oap_mail()"},{"path":"https://rkrug.github.io/openalexPro/reference/oap_mail.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the contact email for OpenAlex requests — oap_mail","text":"character scalar email address, NULL configured.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/oap_mail.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get the contact email for OpenAlex requests — oap_mail","text":"helper mirrors behavior openalexR::oa_email() make easy configure contact address without hard dependency. Supplying valid email helps responsible API usage.","code":""},{"path":[]},{"path":"https://rkrug.github.io/openalexPro/reference/oap_mail.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get the contact email for OpenAlex requests — oap_mail","text":"","code":"Sys.setenv(openalexR.mailto = \"name@example.org\") oap_mail() #> [1] \"name@example.org\"  options(openalexR.mailto = \"name@example.org\") oap_mail() #> [1] \"name@example.org\""},{"path":"https://rkrug.github.io/openalexPro/reference/opt_filter_names.html","id":null,"dir":"Reference","previous_headings":"","what":"Get available filter names from OpenAlex API — opt_filter_names","title":"Get available filter names from OpenAlex API — opt_filter_names","text":"Get available filter names OpenAlex API","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/opt_filter_names.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get available filter names from OpenAlex API — opt_filter_names","text":"","code":"opt_filter_names(update = FALSE)"},{"path":"https://rkrug.github.io/openalexPro/reference/opt_filter_names.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get available filter names from OpenAlex API — opt_filter_names","text":"update logical. `TRUE` update existing value. Default `FALSE`.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/opt_filter_names.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get available filter names from OpenAlex API — opt_filter_names","text":"character vector available filter names","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/opt_select_fields.html","id":null,"dir":"Reference","previous_headings":"","what":"Get available select fields from OpenAlex API — opt_select_fields","title":"Get available select fields from OpenAlex API — opt_select_fields","text":"Get available select fields OpenAlex API","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/opt_select_fields.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get available select fields from OpenAlex API — opt_select_fields","text":"","code":"opt_select_fields(update = FALSE)"},{"path":"https://rkrug.github.io/openalexPro/reference/opt_select_fields.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get available select fields from OpenAlex API — opt_select_fields","text":"update logical. `TRUE` update existing value. Default `FALSE`.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/opt_select_fields.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get available select fields from OpenAlex API — opt_select_fields","text":"character vector available select fields","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/pro_count.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve metadata counts for a PRO API request — pro_count","title":"Retrieve metadata counts for a PRO API request — pro_count","text":"Builds `httr2` request targeting OpenAlex PRO endpoint, executes , extracts pagination metadata. summary metadata requested first page fetched minimise API usage.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/pro_count.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve metadata counts for a PRO API request — pro_count","text":"","code":"pro_count(   query_url,   mailto = oap_mail(),   api_key = oap_apikey,   error_log = NULL )"},{"path":"https://rkrug.github.io/openalexPro/reference/pro_count.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve metadata counts for a PRO API request — pro_count","text":"query_url Character string containing fully constructed OpenAlex PRO endpoint URL. mailto Character string used API `mailto` query parameter request `User-Agent`. Defaults configured `oap_mail()`. api_key Either character string API key function returning one. Defaults `oap_apikey`, gracefully handles `NULL` lazy evaluation. error_log location error log API calls. (default: `NULL` (none)).","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/pro_count.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve metadata counts for a PRO API request — pro_count","text":"named integer vector containing `count`, `db_response_time_ms`,   `page`, `per_page` elements. count negative, size   request larger allowed limit 4094. request fails,   value `NA`.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/pro_count.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Retrieve metadata counts for a PRO API request — pro_count","text":"","code":"if (FALSE) { # \\dontrun{ meta <- pro_count(\"https://api.openalex.org/works?filter=host_venue.id:V123\") meta[[\"count\"]] } # }"},{"path":"https://rkrug.github.io/openalexPro/reference/pro_query.html","id":null,"dir":"Reference","previous_headings":"","what":"Build an OpenAlex request (httr2) — pro_query","title":"Build an OpenAlex request (httr2) — pro_query","text":"Construct httr2 request OpenAlex API. filters must supplied named ... arguments (e.g., from_publication_date = \"2020-01-01\").","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/pro_query.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build an OpenAlex request (httr2) — pro_query","text":"","code":"pro_query(   entity = c(\"works\", \"authors\", \"venues\", \"institutions\", \"concepts\", \"publishers\",     \"funders\"),   id = NULL,   multiple_id = FALSE,   search = NULL,   group_by = NULL,   select = NULL,   options = NULL,   endpoint = \"https://api.openalex.org\",   mailto = NULL,   user_agent = NULL,   chunk_limit = 50L,   ... )"},{"path":"https://rkrug.github.io/openalexPro/reference/pro_query.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build an OpenAlex request (httr2) — pro_query","text":"entity Character; one \"works\", \"authors\", \"venues\", \"institutions\", \"concepts\", \"publishers\", \"funders\". id Optional single ID (e.g., \"W1775749144\") fetch one entity. multiple_id Logical; TRUE id vector, IDs moved ids.openalex filter id cleared. search Optional full-text search string. group_by Optional field group (facets), e.g. \"type\". select Optional character vector fields return. options Optional named list additional query parameters (e.g., list(per_page = 200, sort = \"cited_by_count:desc\", cursor = \"*\", sample = 100)). endpoint Base API URL. Defaults \"https://api.openalex.org\". mailto Optional email join polite pool; added query parameter appended User-Agent. user_agent Optional custom User-Agent. chunk_limit Number DOIS ids per chunk chunked. Default: 50 ... Filters named arguments. Values may scalars vectors (vectors collapsed \"|\" express ).","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/pro_query.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build an OpenAlex request (httr2) — pro_query","text":"individual URL list URLs.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/pro_query.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Build an OpenAlex request (httr2) — pro_query","text":"Filter names validated via .validate_filter() using opt_filter_names(). select fields validated via .validate_select() using `opt_select_fields()`. multiple 50 `doi` openalex `id`s provided, request automatically split chunks 50 named list URLs returned.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/pro_query.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Build an OpenAlex request (httr2) — pro_query","text":"","code":"if (FALSE) { # \\dontrun{  req <- oa_build_req(   entity = \"works\",   search = \"biodiversity\",   from_publication_date = \"2020-01-01\",   language = c(\"en\",\"de\"),   select = c(\"id\",\"title\",\"publication_year\"),   options = list(per_page = 5),   mailto = \"you@example.org\" ) # resp <- api_call(req) # httr2::resp_body_json(resp) } # }"},{"path":"https://rkrug.github.io/openalexPro/reference/pro_request.html","id":null,"dir":"Reference","previous_headings":"","what":"openalexR::oa_request() with additional argument — pro_request","title":"openalexR::oa_request() with additional argument — pro_request","text":"function adds one argument openalexR::oa_request(), namely output. specified, return values OpenAlex saved jaon files directory return value directory json files.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/pro_request.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"openalexR::oa_request() with additional argument — pro_request","text":"","code":"pro_request(   query_url,   pages = 1000,   output = NULL,   overwrite = FALSE,   mailto = oap_mail(),   api_key = oap_apikey,   workers = 1,   verbose = FALSE,   progress = TRUE,   count_only = FALSE,   error_log = NULL )"},{"path":"https://rkrug.github.io/openalexPro/reference/pro_request.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"openalexR::oa_request() with additional argument — pro_request","text":"query_url URL API query list URLs returned pro_query(). pages number pages downloaded. default set 1000, 2,000,000 works. recommended increase beyond 1000 due server load use snapshot instead. NULL, pages downloaded. Default: 1000. output directory JSON files saved. Default temporary directory. NULL, return value call openalexR::oa_request() arguments returned overwrite Logical. TRUE, output deleted already exists. mailto email address user. See oap_mail(). api_key API key user. See oap_apikey. workers Number parallel workers use query_url list. Defaults 1. verbose Logical indicating whether show verbose messages. progress Logical default TRUE indicating whether show progress bar. count_only return count named numeric vector list. error_log location error log API calls. (default: NULL (none)).","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/pro_request.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"openalexR::oa_request() with additional argument — pro_request","text":"count_only FALSE (default) complete path expanded normalized output. count_only TRUE, named numeric vector count works specified query_url(s).","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/pro_request.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"openalexR::oa_request() with additional argument — pro_request","text":"documentation please see openalexR::oa_request() query_url list, function called element list parallel using maximum workers parallel R sessions. results individual URLs list returned folder named names list elements output folder.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/pro_request_jsonl.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert JSON files to jsonl files — pro_request_jsonl","title":"Convert JSON files to jsonl files — pro_request_jsonl","text":"function takes directory JSON files written call pro_request(...) preparing json files processed using DuckDB converting jsonl files. subfolders input_json preserved output, .e. results list initial queries passed pro_request() maintained.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/pro_request_jsonl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert JSON files to jsonl files — pro_request_jsonl","text":"","code":"pro_request_jsonl(   input_json = NULL,   output = NULL,   add_columns = list(),   overwrite = FALSE,   verbose = TRUE,   delete_input = FALSE )"},{"path":"https://rkrug.github.io/openalexPro/reference/pro_request_jsonl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert JSON files to jsonl files — pro_request_jsonl","text":"input_json directory JSON files returned pro_request(..., json_dir = \"FOLDER\"). output output directory jsonl files created calls `jq_execute(). add_columns List additional fields added output. nave provided named list, e./g. list(column_1 = \"value_1\", column_2 = 2). Scalar values supported. overwrite Logical indicating whether overwrite output. verbose Logical indicating whether show verbose information. Defaults TRUE delete_input Determines input_json deleted afterwards. Defaults FALSE.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/pro_request_jsonl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert JSON files to jsonl files — pro_request_jsonl","text":"function returns output invisibly.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/pro_request_jsonl.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convert JSON files to jsonl files — pro_request_jsonl","text":"See jq_execute vignette(\"jq\", package = \"openalexPro\") information conversion JSON files. folder/filename converted value named page example: subfolder output folder called Chunk_1 page othe json file represents 2 resulting cvalus page Chunk_1_2 function uses DuckDB read JSON files create Apache Parquet files. function creates DuckDB connection memory readsds JSON files DuckDB needed. creates SQL query convert JSON files Apache Parquet files copy result specified directory.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/pro_request_jsonl.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert JSON files to jsonl files — pro_request_jsonl","text":"","code":"if (FALSE) { # \\dontrun{   source_to_parquet(   input_json = \"json\",   source_type = \"snapshot\",   output = \"parquet\" ) } # }"},{"path":"https://rkrug.github.io/openalexPro/reference/pro_request_jsonl_parquet.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert JSON files to Apache Parquet files — pro_request_jsonl_parquet","title":"Convert JSON files to Apache Parquet files — pro_request_jsonl_parquet","text":"function takes directory JSONL files written call pro_request_jsonl(...) converts Apache Parquet files. jsonl processed individually, limit number records.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/pro_request_jsonl_parquet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert JSON files to Apache Parquet files — pro_request_jsonl_parquet","text":"","code":"pro_request_jsonl_parquet(   input_jsonl = NULL,   output = NULL,   add_columns = list(),   overwrite = FALSE,   verbose = TRUE,   delete_input = FALSE )"},{"path":"https://rkrug.github.io/openalexPro/reference/pro_request_jsonl_parquet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert JSON files to Apache Parquet files — pro_request_jsonl_parquet","text":"input_jsonl directory JSON files returned pro_request(..., json_dir = \"FOLDER\"). output output directory parquet dataset; default: temporary directory. add_columns List additional fields added output. nave provided named list, e./g. list(column_1 = \"value_1\", column_2 = 2). Scalar values supported. overwrite Logical indicating whether overwrite output. verbose Logical indicating whether show verbose information. Defaults TRUE delete_input Determines input_jsonl deleted afterwards. Defaults FALSE.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/pro_request_jsonl_parquet.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert JSON files to Apache Parquet files — pro_request_jsonl_parquet","text":"function returns output invisibly.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/pro_request_jsonl_parquet.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convert JSON files to Apache Parquet files — pro_request_jsonl_parquet","text":"value page created pro_request_jsonl() used partitioning. jsonl files combined single Apache Parquet dataset, can filtered using \"page\". example: subfolder output folder called Chunk_1 page othe json file represents 2 resulting values page Chunk_1_2 function uses DuckDB read JSON files create Apache Parquet files. function creates DuckDB connection memory readsds JSON files DuckDB needed. creates SQL query convert JSON files Apache Parquet files copy result specified directory.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/pro_snowball.html","id":null,"dir":"Reference","previous_headings":"","what":"A function to perform a snowball search and convert the result to a tibble/data frame. — pro_snowball","title":"A function to perform a snowball search and convert the result to a tibble/data frame. — pro_snowball","text":"function perform snowball search convert result tibble/data frame.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/pro_snowball.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A function to perform a snowball search and convert the result to a tibble/data frame. — pro_snowball","text":"","code":"pro_snowball(   identifier = NULL,   doi = NULL,   output = tempfile(fileext = \".snowball\"),   verbose = FALSE )"},{"path":"https://rkrug.github.io/openalexPro/reference/pro_snowball.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A function to perform a snowball search and convert the result to a tibble/data frame. — pro_snowball","text":"identifier Character vector openalex identifiers. doi Character vector dois. output parquet dataset; default: temporary directory. verbose Logical indicating whether show verbose information. Defaults FALSE","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/pro_snowball.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A function to perform a snowball search and convert the result to a tibble/data frame. — pro_snowball","text":"folder results containing multiple subfolders.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/pro_snowball_extract_edges.html","id":null,"dir":"Reference","previous_headings":"","what":"A function to extract the edges from a parquet database containing the nodes — pro_snowball_extract_edges","title":"A function to extract the edges from a parquet database containing the nodes — pro_snowball_extract_edges","text":"function extract edges parquet database containing nodes","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/pro_snowball_extract_edges.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A function to extract the edges from a parquet database containing the nodes — pro_snowball_extract_edges","text":"","code":"pro_snowball_extract_edges(   nodes = NULL,   output = tempfile(fileext = \".snowball\"),   verbose = FALSE )"},{"path":"https://rkrug.github.io/openalexPro/reference/pro_snowball_extract_edges.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A function to extract the edges from a parquet database containing the nodes — pro_snowball_extract_edges","text":"nodes Path nodes parquet dataset output output folder, parquet database containing edges called edges savedp default: temporary directory. verbose Logical indicating whether show verbose information. Defaults FALSE","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/pro_snowball_extract_edges.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A function to extract the edges from a parquet database containing the nodes — pro_snowball_extract_edges","text":"list containing 2 elements: nodes: dataframe publication records. last column oa_input indicates whether work one input identifier(s). edges: publication link dataframe 2 columns , row , B means -> B means cites B. bibliometrics, \"citation action\" comes B.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/pro_snowball_extract_edges.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A function to extract the edges from a parquet database containing the nodes — pro_snowball_extract_edges","text":"","code":"if (FALSE) { # \\dontrun{  snowball_docs <- pro_snowball(    identifier = c(\"W2741809807\", \"W2755950973\"),    citing_params = list(from_publication_date = \"2022-01-01\"),    cited_by_params = list(),    verbose = TRUE )  # Identical to above, but searches using paper DOIs  snowball_docs_doi <- oa_snowball(    doi = c(\"10.1016/j.joi.2017.08.007\", \"10.7717/peerj.4375\"),    citing_params = list(from_publication_date = \"2022-01-01\"),    cited_by_params = list(),    verbose = TRUE ) } # }"},{"path":"https://rkrug.github.io/openalexPro/reference/pro_snowball_get_nodes.html","id":null,"dir":"Reference","previous_headings":"","what":"A function to get the nodes for a snowball search — pro_snowball_get_nodes","title":"A function to get the nodes for a snowball search — pro_snowball_get_nodes","text":"function get nodes snowball search","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/pro_snowball_get_nodes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A function to get the nodes for a snowball search — pro_snowball_get_nodes","text":"","code":"pro_snowball_get_nodes(   identifier = NULL,   doi = NULL,   limit = NULL,   output = tempfile(fileext = \".snowball\"),   verbose = FALSE )"},{"path":"https://rkrug.github.io/openalexPro/reference/pro_snowball_get_nodes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A function to get the nodes for a snowball search — pro_snowball_get_nodes","text":"identifier Character vector openalex identifiers. doi Character vector dois. limit citedOnly works cited keypaper retrieved, citingOnly retrieves works citing keypaper. Default: NULL retrieved. 'none' equal NULL output parquet dataset; default: temporary directory. verbose Logical indicating whether show verbose information. Defaults FALSE","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/pro_snowball_get_nodes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A function to get the nodes for a snowball search — pro_snowball_get_nodes","text":"Path nodes parquet dataset","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/read_corpus.html","id":null,"dir":"Reference","previous_headings":"","what":"Read corpus from Parquet Dataset — read_corpus","title":"Read corpus from Parquet Dataset — read_corpus","text":"function reads corpus Apache Parquet format returns ArrowObject representing corpus can fed dplyr pipeline tibble contains data.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/read_corpus.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read corpus from Parquet Dataset — read_corpus","text":"","code":"read_corpus(corpus, return_data = FALSE)"},{"path":"https://rkrug.github.io/openalexPro/reference/read_corpus.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read corpus from Parquet Dataset — read_corpus","text":"corpus directory Parquet files. return_data Logical indicating whether return ArrowObject representing corpus (default) tibble containing whole corpus shou,d returned.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/read_corpus.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read corpus from Parquet Dataset — read_corpus","text":"ArrowObject representing corpus tibble.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/read_snowball.html","id":null,"dir":"Reference","previous_headings":"","what":"Read snowball from Parquet Dataset — read_snowball","title":"Read snowball from Parquet Dataset — read_snowball","text":"function reads snowball Apache Parquet format returns list containing nodes edges, can either Arrow Datasets tibbles.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/read_snowball.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read snowball from Parquet Dataset — read_snowball","text":"","code":"read_snowball(   snowball = NULL,   edge_type = c(\"core\", \"extended\", \"outside\"),   return_data = FALSE,   shorten_ids = TRUE )"},{"path":"https://rkrug.github.io/openalexPro/reference/read_snowball.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read snowball from Parquet Dataset — read_snowball","text":"snowball directory Parquet files poppulater pro_snowball(). edge_type type returned edges. Possible values : core: edges keypapers selected extended, edges nodes selected (includes core edges) outside:  edges either nodes multiple allowed. return_data Logical indicating whether return ArrowObject representing corpus (default) tibble containing whole corpus shou,d returned. shorten_ids TRUE ids shortened, .e. part https://openalex.org/ removed","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/read_snowball.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read snowball from Parquet Dataset — read_snowball","text":"list containing two elements: nodes edges, either ArrowObject representing corpus tibbles containing data.","code":""}]
