[{"path":"https://rkrug.github.io/openalexPro/articles/Workflow.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Workflow using openalexPro2","text":"package openalexPro2 extension package openalexR. main difference openalexR processing memory returns result R object, openalexPro2 write results disk. allows processing large corpora. processing done using duckdb package makes possible tro complex queries corpora without need load whole corpus memory.","code":""},{"path":"https://rkrug.github.io/openalexPro/articles/Workflow.html","id":"workflow","dir":"Articles","previous_headings":"","what":"Workflow","title":"Workflow using openalexPro2","text":"workflow using openalexPro2 essentially follows: function openalexPro2::pro_query() used build API query OpenAlex API function openalexPro2::pro_request() used retrieve results OpenAlex API store folder format oif json files returned OpenAlex. function openalexPro2::pro_request_jsonl() cleaning editing json files Json Lines, aka NDJSON, atext file line separate JSON object. details see function openalexPro2::pro_request_jsonl_parquet() used convert json files parquet database TODO: Add plantuml graph TODO add info examles","code":""},{"path":"https://rkrug.github.io/openalexPro/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Rainer M Krug. Maintainer.","code":""},{"path":"https://rkrug.github.io/openalexPro/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Krug RM (2025). openalexPro2: Providing advanced access OpenAlex power user. R package version 0.0.3, https://github.com/rkrug/openalexPro.","code":"@Manual{,   title = {openalexPro2: Providing a more advanced access to OpenAlex for the power user},   author = {Rainer M Krug},   year = {2025},   note = {R package version 0.0.3},   url = {https://github.com/rkrug/openalexPro}, }"},{"path":[]},{"path":[]},{"path":"https://rkrug.github.io/openalexPro/index.html","id":"introduction","dir":"","previous_headings":"","what":"Introduction","title":"Providing a more advanced access to OpenAlex for the power user","text":"package sopplements openalexR providing advanced access OpenAlex power user. openalexR computations conversions memory. extremely useful smaller datasets downloaded OpenAlex, practical larger corpora require much memory. openalexPro2 , contrast, processes smaller batches (.e. individual pages returned OpenAlex API) memory utilises frameworks like DuckDB parquet file format, part Arrow larger amounts need processed. advantage provide tool download several millions records (one project downloaded 5.5. million) possible using openalexR. openalexProo2 uses function openalexR:oa_query() build query, uses download mechaniism download results. core idea package , hinted , load results memory convert (causes memory bottlenecks oepenalexR useful smaller return corpi) rather save page returned, including headers, individual json files directory. json files processed additional functions. One can directly process th json functions, final parquet dataset analysis. planned build additional acompanying packages using data structures provide functions plot snowball searches, analyse corus, etc. final aim make acompanying packages compatible openalexR outputs, one can easily switch one size corpus increases.","code":""},{"path":"https://rkrug.github.io/openalexPro/index.html","id":"design-principles","dir":"","previous_headings":"","what":"Design Principles","title":"Providing a more advanced access to OpenAlex for the power user","text":"Due requirement openalexPro2 handle huge corpi several millions works, efficient storage format needs provided backend. download json files easiest use, retrieval formats suitable. format used package parquet format space efficient retrieveal data (see https://parquet.apache.org/docs/ detailed description format). interfaces example directly dplyr, one can lot processing even collecting actual data, .e. enabling processing larger--memory datasets. addition, link json files, parquet dataset, retrieval works dataset, duckdb package used. ‘DuckDB fast -process analytical database’ described integrates peferfectly parquet ‘json’ files well dplyr pipelines. last wheel puzzle extraction actual references returned json files well conversion abstracts inverted index format returned OpenAlex creation short citations (Author, et al (2020)). done tool jq jqr package.","code":""},{"path":"https://rkrug.github.io/openalexPro/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Providing a more advanced access to OpenAlex for the power user","text":"“stable” version available via r-universe “development” version can installed github using","code":"install.packages('openalexPro2', repos = c('https://rkrug.r-universe.dev', 'https://cloud.r-project.org')) remotes::install_github(\"rkrug/openalexPro\", ref = \"openalexPro2\")"},{"path":"https://rkrug.github.io/openalexPro/index.html","id":"basic-workflow-for-searches","dir":"","previous_headings":"","what":"Basic Workflow for Searches","title":"Providing a more advanced access to OpenAlex for the power user","text":"Depending search query, results either single record, grpouped records table records. workflow can stoped stages, json files can processed using functions.","code":""},{"path":"https://rkrug.github.io/openalexPro/index.html","id":"id_1-define-query","dir":"","previous_headings":"Basic Workflow for Searches","what":"1. Define query","title":"Providing a more advanced access to OpenAlex for the power user","text":"query defined using function openalexR:oa_query(). details arguments use , please see . convenience, re-published openalexPro2 package.","code":"library(openalexPro2)  res <- oa_query(   title_and_abstract.search = \"biodiversity AND conservation AND IPBES\",   entity = \"works\" )"},{"path":"https://rkrug.github.io/openalexPro/index.html","id":"id_2-download-json-files","dir":"","previous_headings":"Basic Workflow for Searches","what":"2. Download json files","title":"Providing a more advanced access to OpenAlex for the power user","text":"returned jsons saved jsons disk folder provided argument output. contain metadata request well results.","code":"json_raw <- \"./json_raw\" openalexPro2::pro_request(   query_url = query_url,   output = json_raw,   verbose = TRUE,   json_dir = \"json_files\"   )"},{"path":"https://rkrug.github.io/openalexPro/index.html","id":"id_3-process-json-files","dir":"","previous_headings":"Basic Workflow for Searches","what":"3. Process json files","title":"Providing a more advanced access to OpenAlex for the power user","text":"processing json files following: extracting results raw json extracting abstracts inverted index format creation short citations results saved folder provided argument output.","code":"json_extracted <- \"./json_extracted\" openalex_jsonl_folder <- openalexPoro2::pro_request_jsonl(   json_dir = \"json_files\",   output = json_extracted,   verbose = TRUE0 )"},{"path":"https://rkrug.github.io/openalexPro/index.html","id":"id_4-convert-to-parquet","dir":"","previous_headings":"Basic Workflow for Searches","what":"4. Convert to parquet","title":"Providing a more advanced access to OpenAlex for the power user","text":"files converted parquet dataset saved individual parquet files folder provided argument output.","code":"parquet <- \"./parquet\" openalexPro2::pro_request_jsonl_parquet(   json_dir = json_extracted,   output = parquet,   verbose = TRUE )"},{"path":"https://rkrug.github.io/openalexPro/index.html","id":"basic-workflow-for-snowball-searches","dir":"","previous_headings":"","what":"Basic Workflow for Snowball Searches","title":"Providing a more advanced access to OpenAlex for the power user","text":"addition “normal” searches, snowball searches implemented. searches based cited citing relationships works. starts key papers identifies papers citing tthen cited .","code":""},{"path":"https://rkrug.github.io/openalexPro/index.html","id":"id_1-define-keypapers","dir":"","previous_headings":"Basic Workflow for Snowball Searches","what":"1. Define Keypapers","title":"Providing a more advanced access to OpenAlex for the power user","text":"keypapers can identified either DOIs OpenAlex ids.","code":""},{"path":"https://rkrug.github.io/openalexPro/index.html","id":"id_2-do-the-snowball-search","dir":"","previous_headings":"Basic Workflow for Snowball Searches","what":"2. Do the snowball search","title":"Providing a more advanced access to OpenAlex for the power user","text":"snowball search creates several sub-folders output folder (assumed called snowball): contain following files: raw json files returned (cited_json, citing_json, keypaper_json), processsed json files (cited_jsonl, citing_jsonl, keypaper_jsonl), parquet database keypaper (keypaper_parquet) nodes edges snowball search parquet databases.","code":"snowball/ ├── cited_json/ ├── cited_jsonl/ ├── citing_json/ ├── citing_jsonl/ ├── edges/ ├── keypaper_json/ ├── keypaper_jsonl/ ├── keypaper_parquet/ └── nodes/"},{"path":"https://rkrug.github.io/openalexPro/index.html","id":"use-openalex-ids","dir":"","previous_headings":"Basic Workflow for Snowball Searches > 2. Do the snowball search","what":"Use OpenAlex ids","title":"Providing a more advanced access to OpenAlex for the power user","text":"","code":"snowball_dir <- \"./snowball_ids\" snowball_docs <- pro_snowball(   identifier = c(\"W2741809807\", \"W2755950973\"),   output = snowball_dir,   verbose = TRUE )"},{"path":"https://rkrug.github.io/openalexPro/index.html","id":"use-dois","dir":"","previous_headings":"Basic Workflow for Snowball Searches > 2. Do the snowball search","what":"Use DOIs","title":"Providing a more advanced access to OpenAlex for the power user","text":"","code":"snowball_dir_dois <- \"./snowball_dois\" oa_snowball(   doi = c(\"10.1016/j.joi.2017.08.007\", \"10.7717/peerj.4375\"),   output = snowball_dir_dois,   verbose = TRUE )"},{"path":"https://rkrug.github.io/openalexPro/index.html","id":"read-data","dir":"","previous_headings":"","what":"Read Data","title":"Providing a more advanced access to OpenAlex for the power user","text":"package provides two convenience function reading obtained data: read_corpus() reads corpus either Dataset object rearn_data = FALSE data.frame, .e. data table, rearn_data = TRUE. read_snowball() reads snowball search. function returns list contains elemends, nodes edges. Depending return_data argument Dataset data.frame. format resulting read_snowball(read_data = TRUE) practical purposes compatible openalexR data.frame tibble output. Dataset can processed using dplyr functions withiut actually reading data. can read data finally dplyr::collect().","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/extract_doi.html","id":null,"dir":"Reference","previous_headings":"","what":"Extract DOIs or Components from Character Vectors — extract_doi","title":"Extract DOIs or Components from Character Vectors — extract_doi","text":"Extracts DOIs specific DOI components (resolver, prefix, suffix) character vector. Assumes element `x` contains one DOI (without resolver).","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/extract_doi.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Extract DOIs or Components from Character Vectors — extract_doi","text":"","code":"extract_doi(   x,   non_doi_value = \"\",   normalize = TRUE,   what = c(\"doi\", \"resolver\", \"prefix\", \"suffix\") )"},{"path":"https://rkrug.github.io/openalexPro/reference/extract_doi.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Extract DOIs or Components from Character Vectors — extract_doi","text":"x character vector potentially containing DOIs (e.g., raw DOIs, DOI URLs, strings embedded DOIs). non_doi_value Value use elements DOI component found. `NULL`, matched elements returned. normalize Logical. `TRUE` (default), convert extracted DOIs suffixes lowercase trim surrounding whitespace. effect `= \"prefix\"` `= \"resolver\"`. extract element. One : \"doi\" full DOI name (prefix + \"/\" + suffix). Example: `\"10.5281/zenodo.1234567\"` (default) \"resolver\" resolver URL (e.g., `\"https://doi.org/\"`, `\"http://dx.doi.org/\"`) present \"prefix\" DOI prefix (e.g., `\"10.5281\"`) \"suffix\" DOI suffix (e.g., `\"zenodo.1234567\"`)","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/extract_doi.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Extract DOIs or Components from Character Vectors — extract_doi","text":"character vector:   - `non_doi_value` `NULL`, vector length `x`, unmatched entries replaced.   - `non_doi_value` `NULL`, vector matched entries.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/extract_doi.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Extract DOIs or Components from Character Vectors — extract_doi","text":"","code":"x <- c(   \"https://doi.org/10.5281/zenodo.1234567\",   \" 10.1000/XYZ456  \",   \"no doi here\",   NA )  extract_doi(x)  # Full DOIs (default) #> [1] \"10.5281/zenodo.1234567\" \"10.1000/xyz456\"         \"\"                       #> [4] \"\"                       extract_doi(x, what = \"resolver\") #> [1] \"https://doi.org/\" \"\"                 \"\"                 \"\"                 extract_doi(x, what = \"prefix\") #> [1] \"10.5281\" \"10.1000\" \"\"        \"\"        extract_doi(x, what = \"suffix\") #> [1] \"zenodo.1234567\" \"xyz456\"         \"\"               \"\"               extract_doi(x, non_doi_value = NA_character_) #> [1] \"10.5281/zenodo.1234567\" \"10.1000/xyz456\"         NA                       #> [4] NA                       extract_doi(x, non_doi_value = NULL) #> [1] \"10.5281/zenodo.1234567\" \"10.1000/xyz456\""},{"path":"https://rkrug.github.io/openalexPro/reference/jq_execute.html","id":null,"dir":"Reference","previous_headings":"","what":"Execute a jq transformation from an OpenAlex-style JSON to JSONL — jq_execute","title":"Execute a jq transformation from an OpenAlex-style JSON to JSONL — jq_execute","text":"function runs jq filter extract records \"results\" array (root type = \"single\"), reconstruct abstract text, generate citation string, optionally add page field. writes result newline-delimited JSON (.jsonl), suitable Arrow DuckDB. details jq filter logic, see vignette(\"jq\", package = \"openalexPro2\").","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/jq_execute.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Execute a jq transformation from an OpenAlex-style JSON to JSONL — jq_execute","text":"","code":"jq_execute(   input_json,   output_jsonl,   add_columns = list(),   jq_filter = NULL,   page = NULL,   type = c(\"results\", \"single\", \"group_by\") )"},{"path":"https://rkrug.github.io/openalexPro/reference/jq_execute.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Execute a jq transformation from an OpenAlex-style JSON to JSONL — jq_execute","text":"input_json Path input JSON file output_jsonl Path output .jsonl file add_columns List additional fields added output. nave provided named list, e./g. `list(column_1 = \"value_1\", column_2 = 2)`. Scalar values supported. jq_filter Optional custom jq filter string. NULL, default filter used. page Optional integer added \"page\" field output record type Either \"results\" (default, expects .results[] array) \"single\" (treat input array records directly)","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/jq_execute.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Execute a jq transformation from an OpenAlex-style JSON to JSONL — jq_execute","text":"Invisibly returns output path","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/load_sql_file.html","id":null,"dir":"Reference","previous_headings":"","what":"Load a SQL file — load_sql_file","title":"Load a SQL file — load_sql_file","text":"Load SQL file, remove comments starting \"–\" return SQL single string.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/load_sql_file.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Load a SQL file — load_sql_file","text":"","code":"load_sql_file(sql_file = NULL)"},{"path":"https://rkrug.github.io/openalexPro/reference/load_sql_file.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Load a SQL file — load_sql_file","text":"sql_file path SQL file.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/load_sql_file.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Load a SQL file — load_sql_file","text":"string containing SQL code c executed e.g.   `DBI::dbExecute(conn, sql)`","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/normalize_parquet.html","id":null,"dir":"Reference","previous_headings":"","what":"Normalize parquet files — normalize_parquet","title":"Normalize parquet files — normalize_parquet","text":"function takes directory parquet files normalizes schemata. NB: partitioning input parquet dataset lost!","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/normalize_parquet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Normalize parquet files — normalize_parquet","text":"","code":"normalize_parquet(   input_dir = NULL,   output_dir = NULL,   overwrite = FALSE,   ROW_GROUP_SIZE = 10000,   ROW_GROUPS_PER_FILE = 1,   delete_input = FALSE )"},{"path":"https://rkrug.github.io/openalexPro/reference/normalize_parquet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Normalize parquet files — normalize_parquet","text":"input_dir directory parquet files parquet dataset. output_dir parquet dataset normalized schemata. Non partitioned, split several files. overwrite Determines uputput parquet database shlud overwritten exists. Defauls FALSE. ROW_GROUP_SIZE Maximum number rows per row group. Smaller sizes reduce memory usage, larger sizes improve compression. Defaults 10000. See: https://duckdb.org/docs/sql/statements/copy#row_group_size details. ROW_GROUPS_PER_FILE Number row groups include output Parquet file. Controls file size write frequency. Defaults 1 See: https://duckdb.org/docs/sql/statements/copy#row_groups_per_file details. delete_input Determines inputdir deleted afterwards. Defaults FALSE.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/normalize_parquet.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Normalize parquet files — normalize_parquet","text":"function return output_dir.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/normalize_parquet.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Normalize parquet files — normalize_parquet","text":"function uses DuckDB normalize schemata. function creates DuckDB connection memory reads parquet files DuckDB needed re-writes non-partitioned parquet database normalized schemata.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/oap_apikey.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the OpenAlex API key for requests — oap_apikey","title":"Get the OpenAlex API key for requests — oap_apikey","text":"Retrieves API key used OpenAlex requests. value taken environment variable openalexR.apikey set; otherwise falls back R option openalexR.apikey. neither defined, NULL returned.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/oap_apikey.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the OpenAlex API key for requests — oap_apikey","text":"","code":"oap_apikey()"},{"path":"https://rkrug.github.io/openalexPro/reference/oap_apikey.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the OpenAlex API key for requests — oap_apikey","text":"character scalar API key, NULL configured.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/oap_apikey.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get the OpenAlex API key for requests — oap_apikey","text":"helper mirrors behavior openalexR::oa_apikey() make easy configure credentials without hard dependency. Prefer setting environment variable non-interactive usage.","code":""},{"path":[]},{"path":"https://rkrug.github.io/openalexPro/reference/oap_apikey.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get the OpenAlex API key for requests — oap_apikey","text":"","code":"# Set via environment (preferred in non-interactive contexts) Sys.setenv(openalexR.apikey = \"<api-key>\") oap_apikey() #> [1] \"<api-key>\"  # Or via options options(openalexR.apikey = \"<api-key>\") oap_apikey() #> [1] \"<api-key>\""},{"path":"https://rkrug.github.io/openalexPro/reference/oap_mail.html","id":null,"dir":"Reference","previous_headings":"","what":"Get the contact email for OpenAlex requests — oap_mail","title":"Get the contact email for OpenAlex requests — oap_mail","text":"Retrieves contact email address used User-Agent header OpenAlex requests. value taken environment variable openalexR.mailto set; otherwise falls back R option openalexR.mailto. neither defined, NULL returned.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/oap_mail.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get the contact email for OpenAlex requests — oap_mail","text":"","code":"oap_mail()"},{"path":"https://rkrug.github.io/openalexPro/reference/oap_mail.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get the contact email for OpenAlex requests — oap_mail","text":"character scalar email address, NULL configured.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/oap_mail.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Get the contact email for OpenAlex requests — oap_mail","text":"helper mirrors behavior openalexR::oa_email() make easy configure contact address without hard dependency. Supplying valid email helps responsible API usage.","code":""},{"path":[]},{"path":"https://rkrug.github.io/openalexPro/reference/oap_mail.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Get the contact email for OpenAlex requests — oap_mail","text":"","code":"Sys.setenv(openalexR.mailto = \"name@example.org\") oap_mail() #> [1] \"name@example.org\"  options(openalexR.mailto = \"name@example.org\") oap_mail() #> [1] \"name@example.org\""},{"path":"https://rkrug.github.io/openalexPro/reference/opt_filter_names.html","id":null,"dir":"Reference","previous_headings":"","what":"Get available filter names from OpenAlex API — opt_filter_names","title":"Get available filter names from OpenAlex API — opt_filter_names","text":"Get available filter names OpenAlex API","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/opt_filter_names.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get available filter names from OpenAlex API — opt_filter_names","text":"","code":"opt_filter_names(update = FALSE)"},{"path":"https://rkrug.github.io/openalexPro/reference/opt_filter_names.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get available filter names from OpenAlex API — opt_filter_names","text":"update logical. `TRUE` update existing value. Default `FALSE`.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/opt_filter_names.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get available filter names from OpenAlex API — opt_filter_names","text":"character vector available filter names","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/opt_select_fields.html","id":null,"dir":"Reference","previous_headings":"","what":"Get available select fields from OpenAlex API — opt_select_fields","title":"Get available select fields from OpenAlex API — opt_select_fields","text":"Get available select fields OpenAlex API","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/opt_select_fields.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Get available select fields from OpenAlex API — opt_select_fields","text":"","code":"opt_select_fields(update = FALSE)"},{"path":"https://rkrug.github.io/openalexPro/reference/opt_select_fields.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Get available select fields from OpenAlex API — opt_select_fields","text":"update logical. `TRUE` update existing value. Default `FALSE`.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/opt_select_fields.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Get available select fields from OpenAlex API — opt_select_fields","text":"character vector available select fields","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/plot_snowball.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot Snowball — plot_snowball","title":"Plot Snowball — plot_snowball","text":"function takes snowball object name, creates two plots: one sized cited_by_count cited_by_count_by_year. plots saved PDF PNG specified path.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/plot_snowball.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot Snowball — plot_snowball","text":"","code":"plot_snowball(   snowball,   size = \"cited_by_count_by_year\",   label = \"citation\",   title = \"Snowball\" )"},{"path":"https://rkrug.github.io/openalexPro/reference/plot_snowball.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot Snowball — plot_snowball","text":"snowball snowball object containing data plotted. size size nodes plot. Can either coumn name snowball$nodes, \"cited_by_count_by_year\" numeric value. \"cited_by_count_by_year\", size calculated dividing number citations number years. numeric, size nodes set value. label label nodes plot. specified, id nodes used. title title plots.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/plot_snowball.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot Snowball — plot_snowball","text":"return value, called side effects.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/plot_snowball.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Plot Snowball — plot_snowball","text":"","code":"if (FALSE) { # \\dontrun{   plot_snowball(snowball, \"example\") } # }"},{"path":"https://rkrug.github.io/openalexPro/reference/pro_query.html","id":null,"dir":"Reference","previous_headings":"","what":"Build an OpenAlex request (httr2) — pro_query","title":"Build an OpenAlex request (httr2) — pro_query","text":"Construct httr2 request OpenAlex API. filters must supplied named ... arguments (e.g., from_publication_date = \"2020-01-01\").","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/pro_query.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build an OpenAlex request (httr2) — pro_query","text":"","code":"pro_query(   entity = c(\"works\", \"authors\", \"venues\", \"institutions\", \"concepts\", \"publishers\",     \"funders\"),   id = NULL,   multiple_id = FALSE,   search = NULL,   group_by = NULL,   select = NULL,   options = NULL,   endpoint = \"https://api.openalex.org\",   mailto = NULL,   user_agent = NULL,   ... )"},{"path":"https://rkrug.github.io/openalexPro/reference/pro_query.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build an OpenAlex request (httr2) — pro_query","text":"entity Character; one \"works\", \"authors\", \"venues\", \"institutions\", \"concepts\", \"publishers\", \"funders\". id Optional single ID (e.g., \"W1775749144\") fetch one entity. multiple_id Logical; TRUE id vector, IDs moved ids.openalex filter id cleared. search Optional full-text search string. group_by Optional field group (facets), e.g. \"type\". select Optional character vector fields return. options Optional named list additional query parameters (e.g., list(per_page = 200, sort = \"cited_by_count:desc\", cursor = \"*\", sample = 100)). endpoint Base API URL. Defaults \"https://api.openalex.org\". mailto Optional email join polite pool; added query parameter appended User-Agent. user_agent Optional custom User-Agent. ... Filters named arguments. Values may scalars vectors (vectors collapsed \"|\" express ).","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/pro_query.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build an OpenAlex request (httr2) — pro_query","text":"httr2 request object, ready api_call().","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/pro_query.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Build an OpenAlex request (httr2) — pro_query","text":"Filter names validated via .validate_filter() using opt_filter_names(). select fields validated via .validate_select() using `opt_select_fields()`.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/pro_query.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Build an OpenAlex request (httr2) — pro_query","text":"","code":"if (FALSE) { # \\dontrun{  req <- oa_build_req(   entity = \"works\",   search = \"biodiversity\",   from_publication_date = \"2020-01-01\",   language = c(\"en\",\"de\"),   select = c(\"id\",\"title\",\"publication_year\"),   options = list(per_page = 5),   mailto = \"you@example.org\" ) # resp <- api_call(req) # httr2::resp_body_json(resp) } # }"},{"path":"https://rkrug.github.io/openalexPro/reference/pro_request.html","id":null,"dir":"Reference","previous_headings":"","what":"openalexR::oa_request() with additional argument — pro_request","title":"openalexR::oa_request() with additional argument — pro_request","text":"function adds one argument openalexR::oa_request(), namely output. specified, return values OpenAlex saved jaon files directory return value directory json files.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/pro_request.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"openalexR::oa_request() with additional argument — pro_request","text":"","code":"pro_request(   query_url,   pages = 1000,   output = NULL,   overwrite = FALSE,   mailto = oap_mail(),   api_key = oap_apikey,   verbose = FALSE,   progress = TRUE )"},{"path":"https://rkrug.github.io/openalexPro/reference/pro_request.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"openalexR::oa_request() with additional argument — pro_request","text":"query_url URL API query. pages number pages downloaded. default set 1000, 2,000,000 works. recommended increase beyond 1000 due server load use snapshot instead. NULL, pages downloaded. Default: 1000. output directory JSON files saved. Default temporary directory. NULL, return value call openalexR::oa_request() arguments returned overwrite Logical. TRUE, output deleted already exists. mailto email address user. See oap_mail(). api_key API key user. See oap_apikey. verbose Logical indicating whether show verbose messages. progress Logical default TRUE indicating whether show progress bar.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/pro_request.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"openalexR::oa_request() with additional argument — pro_request","text":"output NULL, return value call openalexR::oa_request(), otherwise complete path expanded normalized output.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/pro_request.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"openalexR::oa_request() with additional argument — pro_request","text":"documentation please see openalexR::oa_request()","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/pro_request_jsonl.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert JSON files to Apache Parquet files — pro_request_jsonl","title":"Convert JSON files to Apache Parquet files — pro_request_jsonl","text":"function takes directory JSON files written call pro_request(..., output = \"FOLDER\") preparing json files processed using DuckDB. See","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/pro_request_jsonl.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert JSON files to Apache Parquet files — pro_request_jsonl","text":"","code":"pro_request_jsonl(   input_json = NULL,   output = NULL,   add_columns = list(),   overwrite = FALSE,   verbose = TRUE,   delete_input = FALSE )"},{"path":"https://rkrug.github.io/openalexPro/reference/pro_request_jsonl.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert JSON files to Apache Parquet files — pro_request_jsonl","text":"input_json directory JSON files returned pro_request(..., json_dir = \"FOLDER\"). output output directory jsonl files created calls `jq_execute(). add_columns List additional fields added output. nave provided named list, e./g. list(column_1 = \"value_1\", column_2 = 2). Scalar values supported. overwrite Logical indicating whether overwrite output. verbose Logical indicating whether show verbose information. Defaults TRUE delete_input Determines input_json deleted afterwards. Defaults FALSE.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/pro_request_jsonl.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert JSON files to Apache Parquet files — pro_request_jsonl","text":"function returns output invisibly.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/pro_request_jsonl.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convert JSON files to Apache Parquet files — pro_request_jsonl","text":"See jq_execute vignette(\"jq\", package = \"openalexPro2\") information conversion JSON files. function uses DuckDB read JSON files create Apache Parquet files. function creates DuckDB connection memory readsds JSON files DuckDB needed. creates SQL query convert JSON files Apache Parquet files copy result specified directory.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/pro_request_jsonl.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Convert JSON files to Apache Parquet files — pro_request_jsonl","text":"","code":"if (FALSE) { # \\dontrun{   source_to_parquet(   input_json = \"json\",   source_type = \"snapshot\",   output = \"parquet\" ) } # }"},{"path":"https://rkrug.github.io/openalexPro/reference/pro_request_jsonl_parquet.html","id":null,"dir":"Reference","previous_headings":"","what":"Convert JSON files to Apache Parquet files — pro_request_jsonl_parquet","title":"Convert JSON files to Apache Parquet files — pro_request_jsonl_parquet","text":"function takes directory JSON files written call pro_request(..., json_dir = \"FOLDER\") converts Apache Parquet dataset partitiond page.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/pro_request_jsonl_parquet.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Convert JSON files to Apache Parquet files — pro_request_jsonl_parquet","text":"","code":"pro_request_jsonl_parquet(   input_jsonl = NULL,   output = NULL,   add_columns = list(),   overwrite = FALSE,   verbose = TRUE,   delete_input = FALSE )"},{"path":"https://rkrug.github.io/openalexPro/reference/pro_request_jsonl_parquet.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Convert JSON files to Apache Parquet files — pro_request_jsonl_parquet","text":"input_jsonl directory JSON files returned pro_request(..., json_dir = \"FOLDER\"). output output directory parquet dataset; default: temporary directory. add_columns List additional fields added output. nave provided named list, e./g. list(column_1 = \"value_1\", column_2 = 2). Scalar values supported. overwrite Logical indicating whether overwrite output. verbose Logical indicating whether show verbose information. Defaults TRUE delete_input Determines input_jsonl deleted afterwards. Defaults FALSE.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/pro_request_jsonl_parquet.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Convert JSON files to Apache Parquet files — pro_request_jsonl_parquet","text":"function returns output invisibly.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/pro_request_jsonl_parquet.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Convert JSON files to Apache Parquet files — pro_request_jsonl_parquet","text":"function uses DuckDB read JSON files create Apache Parquet files. function creates DuckDB connection memory readsds JSON files DuckDB needed. creates SQL query convert JSON files Apache Parquet files copy result specified directory.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/pro_snowball.html","id":null,"dir":"Reference","previous_headings":"","what":"A function to perform a snowball search and convert the result to a tibble/data frame. — pro_snowball","title":"A function to perform a snowball search and convert the result to a tibble/data frame. — pro_snowball","text":"function perform snowball search convert result tibble/data frame.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/pro_snowball.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A function to perform a snowball search and convert the result to a tibble/data frame. — pro_snowball","text":"","code":"pro_snowball(   identifier = NULL,   doi = NULL,   output = tempfile(fileext = \".snowball\"),   verbose = FALSE )"},{"path":"https://rkrug.github.io/openalexPro/reference/pro_snowball.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A function to perform a snowball search and convert the result to a tibble/data frame. — pro_snowball","text":"identifier Character vector openalex identifiers. doi Character vector dois. output parquet dataset; default: temporary directory. verbose Logical indicating whether show verbose information. Defaults FALSE","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/pro_snowball.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A function to perform a snowball search and convert the result to a tibble/data frame. — pro_snowball","text":"list containing 2 elements: nodes: dataframe publication records. last column oa_input indicates whether work one input identifier(s). edges: publication link dataframe 2 columns , row , B means -> B means cites B. bibliometrics, \"citation action\" comes B.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/pro_snowball_extract_edges.html","id":null,"dir":"Reference","previous_headings":"","what":"A function to extract the edges from a parquet database containing the nodes — pro_snowball_extract_edges","title":"A function to extract the edges from a parquet database containing the nodes — pro_snowball_extract_edges","text":"function extract edges parquet database containing nodes","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/pro_snowball_extract_edges.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A function to extract the edges from a parquet database containing the nodes — pro_snowball_extract_edges","text":"","code":"pro_snowball_extract_edges(   nodes = NULL,   output = tempfile(fileext = \".snowball\"),   verbose = FALSE )"},{"path":"https://rkrug.github.io/openalexPro/reference/pro_snowball_extract_edges.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A function to extract the edges from a parquet database containing the nodes — pro_snowball_extract_edges","text":"nodes Path nodes parquet dataset output output folder, parquet database containing edges called edges savedp default: temporary directory. verbose Logical indicating whether show verbose information. Defaults FALSE","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/pro_snowball_extract_edges.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A function to extract the edges from a parquet database containing the nodes — pro_snowball_extract_edges","text":"list containing 2 elements: nodes: dataframe publication records. last column oa_input indicates whether work one input identifier(s). edges: publication link dataframe 2 columns , row , B means -> B means cites B. bibliometrics, \"citation action\" comes B.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/pro_snowball_extract_edges.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"A function to extract the edges from a parquet database containing the nodes — pro_snowball_extract_edges","text":"","code":"if (FALSE) { # \\dontrun{  snowball_docs <- pro_snowball(    identifier = c(\"W2741809807\", \"W2755950973\"),    citing_params = list(from_publication_date = \"2022-01-01\"),    cited_by_params = list(),    verbose = TRUE )  # Identical to above, but searches using paper DOIs  snowball_docs_doi <- oa_snowball(    doi = c(\"10.1016/j.joi.2017.08.007\", \"10.7717/peerj.4375\"),    citing_params = list(from_publication_date = \"2022-01-01\"),    cited_by_params = list(),    verbose = TRUE ) } # }"},{"path":"https://rkrug.github.io/openalexPro/reference/pro_snowball_get_nodes.html","id":null,"dir":"Reference","previous_headings":"","what":"A function to get the nodes for a snowball search — pro_snowball_get_nodes","title":"A function to get the nodes for a snowball search — pro_snowball_get_nodes","text":"function get nodes snowball search","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/pro_snowball_get_nodes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"A function to get the nodes for a snowball search — pro_snowball_get_nodes","text":"","code":"pro_snowball_get_nodes(   identifier = NULL,   doi = NULL,   output = tempfile(fileext = \".snowball\"),   verbose = FALSE )"},{"path":"https://rkrug.github.io/openalexPro/reference/pro_snowball_get_nodes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"A function to get the nodes for a snowball search — pro_snowball_get_nodes","text":"identifier Character vector openalex identifiers. doi Character vector dois. output parquet dataset; default: temporary directory. verbose Logical indicating whether show verbose information. Defaults FALSE","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/pro_snowball_get_nodes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"A function to get the nodes for a snowball search — pro_snowball_get_nodes","text":"Path nodes parquet dataset","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/read_corpus.html","id":null,"dir":"Reference","previous_headings":"","what":"Read corpus from Parquet Dataset — read_corpus","title":"Read corpus from Parquet Dataset — read_corpus","text":"function reads corpus Apache Parquet format returns ArrowObject representing corpus can fed dplyr pipeline tibble contains data.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/read_corpus.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read corpus from Parquet Dataset — read_corpus","text":"","code":"read_corpus(corpus, return_data = FALSE)"},{"path":"https://rkrug.github.io/openalexPro/reference/read_corpus.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read corpus from Parquet Dataset — read_corpus","text":"corpus directory Parquet files. return_data Logical indicating whether return ArrowObject representing corpus (default) tibble containing whole corpus shou,d returned.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/read_corpus.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read corpus from Parquet Dataset — read_corpus","text":"ArrowObject representing corpus tibble.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/read_snowball.html","id":null,"dir":"Reference","previous_headings":"","what":"Read snowball from Parquet Dataset — read_snowball","title":"Read snowball from Parquet Dataset — read_snowball","text":"function reads snowball Apache Parquet format returns list containing nodes edges, can either Arrow Datasets tibbles.","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/read_snowball.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Read snowball from Parquet Dataset — read_snowball","text":"","code":"read_snowball(   snowball = NULL,   edge_type = c(\"core\", \"extended\", \"outside\"),   return_data = FALSE,   shorten_ids = TRUE )"},{"path":"https://rkrug.github.io/openalexPro/reference/read_snowball.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Read snowball from Parquet Dataset — read_snowball","text":"snowball directory Parquet files poppulater pro_snowball(). edge_type type returned edges. Possible values : core: edges keypapers selected extended, edges nodes selected (includes core edges) outside:  edges either nodes multiple allowed. return_data Logical indicating whether return ArrowObject representing corpus (default) tibble containing whole corpus shou,d returned. shorten_ids TRUE ids shortened, .e. part https://openalex.org/ removed","code":""},{"path":"https://rkrug.github.io/openalexPro/reference/read_snowball.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Read snowball from Parquet Dataset — read_snowball","text":"list containing two elements: nodes edges, either ArrowObject representing corpus tibbles containing data.","code":""}]
